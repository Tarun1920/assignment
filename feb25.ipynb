{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d5d9dc-2e7b-496f-af12-ff66a25294f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df44c4cf-9d5f-4f8a-ac65-711553fa3b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc (Label-based selection):\n",
    "loc is primarily used for selection by label. You specify the rows and columns you want to select based on their labels (names).\n",
    "It uses inclusive slicing, which means that the end label is included in the selection.\n",
    "You can use labels to select both rows and columns. For example, df.loc[row_labels, column_labels] selects specific rows and columns based on their labels.\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n",
    "selected_data = df.loc[0:1, ['A']]\n",
    "\n",
    "\n",
    "iloc (Integer-based selection):\n",
    "iloc is used for selection by integer index. You specify the rows and columns you want to select based on their integer positions (0-based index).\n",
    "It uses exclusive slicing, which means that the end index is not included in the selection.\n",
    "You can use integers to select both rows and columns. For example, df.iloc[row_indices, column_indices] selects specific rows and columns based on their integer positions.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n",
    "selected_data = df.iloc[0:2, [0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2293a7f0-dbdb-40ce-934b-18b478990966",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5983b6f6-e128-46c7-be3c-079c3de61d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of new_df.loc[2]: A    30\n",
      "Name: 2, dtype: int64\n",
      "Output of new_df.iloc[2]: A    20\n",
      "Name: 1, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Assuming you have a DataFrame df:\n",
    "import pandas as pd\n",
    "\n",
    "data = {'A': [10, 20, 30, 40]}\n",
    "df = pd.DataFrame(data)\n",
    "reindex = [3, 0, 1, 2]\n",
    "new_df = df.reindex(reindex)\n",
    "\n",
    "output_loc = new_df.loc[2]\n",
    "output_iloc = new_df.iloc[2]\n",
    "\n",
    "print(\"Output of new_df.loc[2]:\", output_loc)\n",
    "print(\"Output of new_df.iloc[2]:\", output_iloc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2e8007-8879-40d6-84ef-613dbae16fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a71be1b-8d02-4e72-94ff-4ba294e3aec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of each column:\n",
      "column_1    0.773332\n",
      "column_2    0.574630\n",
      "column_3    0.542678\n",
      "column_4    0.766006\n",
      "column_5    0.527176\n",
      "column_6    0.267783\n",
      "dtype: float64\n",
      "\n",
      "Standard Deviation of 'column_2': 0.2556335208163785\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "columns = ['column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6']\n",
    "indices = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "# Creating a dataframe\n",
    "df1 = pd.DataFrame(np.random.rand(6, 6), columns=columns, index=indices)\n",
    "\n",
    "# (i) Mean of each column\n",
    "column_means = df1.mean()\n",
    "print(\"Mean of each column:\")\n",
    "print(column_means)\n",
    "\n",
    "# (ii) Standard deviation of 'column_2'\n",
    "std_dev_column_2 = df1['column_2'].std()\n",
    "print(\"\\nStandard Deviation of 'column_2':\", std_dev_column_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e380b710-3108-4b04-b5f8-701ab99b88ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec06de50-42b1-4d94-9eb1-0d51314b0b0e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'float' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m df1\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumn_2\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m string_value\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Now, the data type of 'column_2' is object (string), and you can find the mean\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m mean_column_2 \u001b[38;5;241m=\u001b[39m \u001b[43mdf1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcolumn_2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumn_2\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m after replacing the data:\u001b[39m\u001b[38;5;124m\"\u001b[39m, mean_column_2)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:11847\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.mean\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11829\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[1;32m  11830\u001b[0m     _num_doc,\n\u001b[1;32m  11831\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn the mean of the values over the requested axis.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11845\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  11846\u001b[0m ):\n\u001b[0;32m> 11847\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNDFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:11401\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11393\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[1;32m  11394\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  11395\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m lib\u001b[38;5;241m.\u001b[39mNoDefault \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mno_default,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11399\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  11400\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m> 11401\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stat_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  11402\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnanops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m  11403\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:11353\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[0;34m(self, name, func, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11343\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m  11344\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing the level keyword in DataFrame and Series aggregations is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m  11345\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated and will be removed in a future version. Use groupby \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11348\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m  11349\u001b[0m     )\n\u001b[1;32m  11350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_by_level(\n\u001b[1;32m  11351\u001b[0m         name, axis\u001b[38;5;241m=\u001b[39maxis, level\u001b[38;5;241m=\u001b[39mlevel, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only\n\u001b[1;32m  11352\u001b[0m     )\n\u001b[0;32m> 11353\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  11354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\n\u001b[1;32m  11355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/series.py:4816\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   4812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m   4813\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not implement \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4814\u001b[0m     )\n\u001b[1;32m   4815\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 4816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelegate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:93\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 93\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# we want to transform an object array\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;66;03m# ValueError message to the more typical TypeError\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;66;03m# e.g. this is normally a disallowed function on\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;66;03m# object arrays that contain strings\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(args[\u001b[38;5;241m0\u001b[39m]):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:155\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    153\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43malt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:418\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[0;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    416\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[0;32m--> 418\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[1;32m    421\u001b[0m     result \u001b[38;5;241m=\u001b[39m _wrap_results(result, orig_values\u001b[38;5;241m.\u001b[39mdtype, fill_value\u001b[38;5;241m=\u001b[39miNaT)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/nanops.py:706\u001b[0m, in \u001b[0;36mnanmean\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    703\u001b[0m     dtype_count \u001b[38;5;241m=\u001b[39m dtype\n\u001b[1;32m    705\u001b[0m count \u001b[38;5;241m=\u001b[39m _get_counts(values\u001b[38;5;241m.\u001b[39mshape, mask, axis, dtype\u001b[38;5;241m=\u001b[39mdtype_count)\n\u001b[0;32m--> 706\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m _ensure_numeric(\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_sum\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    708\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    709\u001b[0m     count \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, count)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:48\u001b[0m, in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     47\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'float' and 'str'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "columns = ['column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6']\n",
    "indices = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "# Creating a DataFrame\n",
    "df1 = pd.DataFrame(np.random.rand(6, 6), columns=columns, index=indices)\n",
    "\n",
    "# Replace the data in the second row of 'column_2' with a string\n",
    "string_value = \"This is a string\"  # Replace this with the desired string\n",
    "df1.loc[2, 'column_2'] = string_value\n",
    "\n",
    "# Now, the data type of 'column_2' is object (string), and you can find the mean\n",
    "mean_column_2 = df1['column_2'].mean()\n",
    "print(\"Mean of 'column_2' after replacing the data:\", mean_column_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a498a1-60a4-4d31-9585-9c36b457f2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "In this code, we first replace the data in the second row of 'column_2' with a string value and then calculate the mean of 'column_2'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae53f0bc-dfb5-4b74-b3f2-b6002be25c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022fcc7f-5189-4a8b-ac7c-8692d13dd883",
   "metadata": {},
   "outputs": [],
   "source": [
    "window functions\" refers to a group of functions that are used to perform operations on a specific \"window\" of data within a DataFrame or Series. These functions allow you to compute aggregate or transformation operations over a moving or fixed window of data, such as a rolling window of a specific size or a window defined by a time-based or index-based interva\n",
    "\n",
    "Some common types of window functions in Pandas include\n",
    "\n",
    "Rolling Functions:\n",
    "\n",
    "Rolling functions operate on a rolling or moving window of data. You can specify the window size, and the function calculates aggregates (e.g., mean, sum, variance) over this rolling window as it moves through the data.\n",
    "\n",
    "Expanding Functions:\n",
    "\n",
    "Expanding functions compute aggregates for an expanding window that starts from the beginning of the data and grows as it moves through the data. This is useful for calculating cumulative statistics.\n",
    "\n",
    "EWM (Exponentially Weighted Moving) Functions:\n",
    "\n",
    "EWM functions apply exponential weighting to the data within a window. They are useful for smoothing data and giving more weight to recent observations.\n",
    "\n",
    "Window Functions with GroupBy:\n",
    "\n",
    "You can apply window functions within groups created using groupby. This allows you to compute statistics separately for each group, considering the window within each group.\n",
    "\n",
    "Aggregating and Transforming:\n",
    "\n",
    "Window functions can be used to perform various aggregation and transformation operations within the specified windows, including custom functions defined by users.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c70d1ff-ecd0-4802-b7ea-7d88506fda2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6beac401-88c8-4ffa-8964-34772319d027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Month: 10\n",
      "Current Year: 2023\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Get the current date and time\n",
    "current_datetime = pd.Timestamp.now()\n",
    "\n",
    "# Extract the current month and year\n",
    "current_month = current_datetime.month\n",
    "current_year = current_datetime.year\n",
    "\n",
    "print(f\"Current Month: {current_month}\")\n",
    "print(f\"Current Year: {current_year}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3662b9ef-baa0-4b1c-8f16-b234d4571e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "390a5813-3310-48c5-9f95-9b27e6d0ab99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the first date (YYYY-MM-DD):  2001-12-23\n",
      "Enter the second date (YYYY-MM-DD):  2023-10-15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Difference: 7966 days, 0 hours, 0 minutes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Prompt the user to enter the two dates\n",
    "date_str1 = input(\"Enter the first date (YYYY-MM-DD): \")\n",
    "date_str2 = input(\"Enter the second date (YYYY-MM-DD): \")\n",
    "\n",
    "# Convert the input date strings to datetime objects\n",
    "date1 = pd.to_datetime(date_str1, format='%Y-%m-%d')\n",
    "date2 = pd.to_datetime(date_str2, format='%Y-%m-%d')\n",
    "\n",
    "# Calculate the time difference\n",
    "time_difference = date2 - date1\n",
    "\n",
    "# Extract days, hours, and minutes from the time difference\n",
    "days = time_difference.days\n",
    "hours, remainder = divmod(time_difference.seconds, 3600)\n",
    "minutes = remainder // 60\n",
    "\n",
    "# Display the result\n",
    "print(f\"Time Difference: {days} days, {hours} hours, {minutes} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9543e44c-30ea-4d2e-b73f-26ad767a75ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189857ca-9277-4b00-b7ac-04e0d709de75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Prompt the user to enter the file path\n",
    "file_path = input(\"Enter the CSV file path: \")\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Prompt the user to enter the column name to convert to categorical\n",
    "column_name = input(\"Enter the column name to convert to categorical: \")\n",
    "\n",
    "# Prompt the user to enter the category order (comma-separated values)\n",
    "category_order = input(\"Enter the category order (comma-separated values): \").split(',')\n",
    "\n",
    "# Convert the specified column to categorical data type\n",
    "df[column_name] = pd.Categorical(df[column_name], categories=category_order, ordered=True)\n",
    "\n",
    "# Sort the DataFrame based on the categorical column\n",
    "sorted_df = df.sort_values(by=[column_name])\n",
    "\n",
    "# Display the sorted data\n",
    "print(\"Sorted Data:\")\n",
    "print(sorted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea706aa-6472-4376-bc3f-52e91f4fad85",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6665bcd5-e3e3-4a9c-96c2-2eec26c3528d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prompt the user to enter the file path\n",
    "file_path = input(\"Enter the CSV file path: \")\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Assuming the CSV file has a date column, product category column, and sales column\n",
    "# Adjust column names as needed\n",
    "date_column = \"Date\"\n",
    "category_column = \"ProductCategory\"\n",
    "sales_column = \"Sales\"\n",
    "\n",
    "# Convert the date column to a datetime object\n",
    "df[date_column] = pd.to_datetime(df[date_column])\n",
    "\n",
    "# Pivot the DataFrame to create a table suitable for a stacked bar chart\n",
    "pivot_df = df.pivot(index=date_column, columns=category_column, values=sales_column).fillna(0)\n",
    "\n",
    "# Create a stacked bar chart\n",
    "ax = pivot_df.plot(kind=\"bar\", stacked=True, figsize=(10, 6))\n",
    "plt.title(\"Sales by Product Category Over Time\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Sales\")\n",
    "plt.legend(title=category_column, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Display the chart\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be2dbdc-437a-469a-acb2-529a0ef7146a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e61fda0-6af9-4432-8475-3de39abbb801",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "# Prompt the user to enter the file path\n",
    "file_path = input(\"Enter the file path of the CSV file containing student data: \")\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Calculate the mean, median, and mode of the test scores\n",
    "mean_score = df['Test Score'].mean()\n",
    "median_score = df['Test Score'].median()\n",
    "mode_scores = df['Test Score'].mode().tolist()\n",
    "\n",
    "# Create a PrettyTable for displaying the results\n",
    "result_table = PrettyTable()\n",
    "result_table.field_names = [\"Statistic\", \"Value\"]\n",
    "result_table.add_row([\"Mean\", mean_score])\n",
    "result_table.add_row([\"Median\", median_score])\n",
    "result_table.add_row([\"Mode\", ', '.join(map(str, mode_scores))])\n",
    "\n",
    "# Display the table\n",
    "print(result_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0848c89e-f18b-4875-ab17-e0f2ed59d666",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9160907a-1463-4fab-ae39-4bf8eaba325e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fde543-28a1-445c-8270-63b018a6a59c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
